{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759923f6",
   "metadata": {},
   "source": [
    "# Auto Correct Using Probabilistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa55b9",
   "metadata": {},
   "source": [
    "In this notebook we will implement an Auto-correct Model that was first created by [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) in 2007.<br>His [original article](https://norvig.com/spell-correct.html) may be a useful reference for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431a2e7",
   "metadata": {},
   "source": [
    "### Simply an Auto-correct model is implementing these steps:\n",
    "1. Identify Mispelled Words\n",
    "2. Find words that are **N** edit distance away\n",
    "- Edit Distances are operations performed on a word to change it to another word (check Below Cell)\n",
    "3. Filter Candidates from generated word\n",
    "4. Calculate Word Probability for Each Candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcf960",
   "metadata": {},
   "source": [
    "#### Edit Distance\n",
    "\n",
    "In this notebook, I will implement models that correct words that are 1 and 2 edit distances away. \n",
    "- We say two words are n edit distance away from each other when we need n edits to change one word into another. \n",
    "\n",
    "An edit could consist of one of the following options: \n",
    "\n",
    "- Delete (remove a letter): ‘hat’ => ‘at, ha, ht’\n",
    "- Switch (swap 2 adjacent letters): ‘eta’ => ‘eat, tea,...’\n",
    "- Replace (change 1 letter to another): ‘jat’ => ‘hat, rat, cat, mat, ...’\n",
    "- Insert (add a letter): ‘te’ => ‘the, ten, ate, ...’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a2a91d",
   "metadata": {},
   "source": [
    "#### Word Probability\n",
    "A word probability could be simply calculated as:\n",
    "$$P(c) = \\frac{count(c)}{V} $$\n",
    "Where $P(c) $ is the probability of correct word<br>\n",
    "and $count(c) $ is the number of occurences of the word **c** in the vocabulary<br>\n",
    "and $V $ is the total words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5686e14",
   "metadata": {},
   "source": [
    "With that being said, Let's start our notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0258b",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "As in any other machine learning task, the first thing you have to do is process your data set.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12541652",
   "metadata": {},
   "source": [
    "we will generate our vocabulary using **Shakespere.txt** file<br>\n",
    "1. We will read the file\n",
    "2. Lowercase every word\n",
    "3. Return List of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8656c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file_name which is found in your current directory. You just have to read it in. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus (text file you read) in lower case. \n",
    "    \"\"\"\n",
    "    words = []\n",
    "    \n",
    "    #Open the file, read its contents into a string variable\n",
    "    with open(file_name) as file:\n",
    "        string = file.read()\n",
    "        \n",
    "    # convert all letters to lower case\n",
    "    lowered_string = string.lower()\n",
    "    \n",
    "    #Convert every word to lower case and return them in a list.\n",
    "    texts = [sub_text for sub_text in lowered_string.split(\" \")]\n",
    "\n",
    "    pattern = \"[a-zA-Z0-9]+\"\n",
    "\n",
    "    for text in texts:\n",
    "        matches = re.findall(pattern, text)\n",
    "        for match in matches:\n",
    "            words.append(match)\n",
    "                \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9cbde12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
      "There are 6116 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "word_l = process_data('./data/shakespeare.txt')\n",
    "vocab = set(word_l)  # this will be your new vocabulary\n",
    "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852dd1ea",
   "metadata": {},
   "source": [
    "#### Now I'll Implement a get_count function that returns a dictionary\n",
    "- The dictionary's keys are words\n",
    "- The value for each word is the number of times that word appears in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb269922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word_l):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''   \n",
    "    word_count_dict = {}\n",
    "    \n",
    "    for word in word_l:\n",
    "        word_count_dict[word] = word_count_dict.get(word,0) + 1\n",
    "        \n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d43c86f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 key values pairs\n",
      "The count for the word 'happy' is 17\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = get_count(word_l)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"The count for the word 'happy' is {word_count_dict.get('happy',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712704d",
   "metadata": {},
   "source": [
    "<HR></HR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e46a01",
   "metadata": {},
   "source": [
    "#### Now I'll Implement a get_probs function that returns a dictionary\n",
    "Given the dictionary of word counts, I'll compute the probability that each word will appear if randomly selected from the corpus of words.<br>\n",
    "$$P(c) = \\frac{count(c)}{V} $$\n",
    "Where $P(c) $ is the probability of correct word<br>\n",
    "and $count(c) $ is the number of occurences of the word **c** in the vocabulary<br>\n",
    "and $V $ is the total words in the vocabulary\n",
    "\n",
    "#### get_probs function which gives you the probability that a word occurs in a sample. This returns a dictionary where\n",
    "- keys are words \n",
    "- value for each word is its probability in the corpus of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44398d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}\n",
    "    \n",
    "    for word in list(word_count_dict.keys()):\n",
    "        probs[word] = (word_count_dict[word])  / (np.sum(np.array(list(word_count_dict.values()))))\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff32769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 6116\n",
      "P('happy') is 0.0003\n"
     ]
    }
   ],
   "source": [
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('happy') is {probs['happy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807ead6",
   "metadata": {},
   "source": [
    "<HR></HR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812b5b3",
   "metadata": {},
   "source": [
    "# Word Operations\n",
    "\n",
    "Now that you have computed $P(c)$ for all the words in the corpus, you will write a few functions that performs operations to words so that it can change mispelled words and return the right spellings of the words. I will implement four functions: \n",
    "\n",
    "* delete_letter : given a word, it returns all the possible strings that have **one character removed**. \n",
    "* switch_letter: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
    "* replace_letter: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
    "* insert_letter: given a word, it returns all the possible strings that have an **additional character inserted**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799df18",
   "metadata": {},
   "source": [
    "### Delete Operations\n",
    "I will implement a delete_letter() function that, given a word, returns a list of strings with one character deleted. \n",
    "\n",
    "For example, given the word **nice**, it would return the set: {'ice', 'nce', 'nic', 'nie'}. \n",
    "\n",
    "Create a list of 'splits'. This is all the ways you can split a word into Left and Right: For example: <br>\n",
    "nice is split into : **[('', 'nice'), ('n', 'ice'), ('ni', 'ce'), ('nic', 'e'), ('nice', '')]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5efb729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    \n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    delete_l = [L+R[1:] for L,R in split_l]\n",
    "    \n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return  delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8997ff28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word cans, \n",
      "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's')], \n",
      "delete_l = ['ans', 'cns', 'cas', 'can']\n",
      "\n",
      "Number of outputs of delete_letter('at') is 2\n"
     ]
    }
   ],
   "source": [
    "delete_word_l = delete_letter(word=\"cans\", verbose=True)\n",
    "print()\n",
    "print(f\"Number of outputs of delete_letter('at') is {len(delete_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6891d",
   "metadata": {},
   "source": [
    "### Switch Operations\n",
    "I will implement a switch_letter() function switches two letters in a word.<br> It takes in a word and returns a list of all the possible switches of two letters **that are adjacent to each other**. \n",
    "\n",
    "For example, given the word **'eta'**, it returns {'eat', 'tea'}, but does not return 'ate'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef192bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    switch_l = [L[:-1]+R[0]+L[-1]+R[1:] for L,R in split_l if L and R]\n",
    "    \n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "    \n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e497fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = eta \n",
      "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a')] \n",
      "switch_l = ['tea', 'eat']\n",
      "\n",
      "Number of outputs of switch_letter('at') is 1\n"
     ]
    }
   ],
   "source": [
    "switch_word_l = switch_letter(word=\"eta\", verbose=True)\n",
    "print()\n",
    "print(f\"Number of outputs of switch_letter('at') is {len(switch_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e800b",
   "metadata": {},
   "source": [
    "### Replace Operations\n",
    "I will implement a replace_letter() function that takes in a word and returns a list of strings with one replaced letter from the original word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b76b3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    replace_l = [L+N+R[1:] for L,R in split_l for N in letters if N != R[0]]\n",
    "    replace_set = set(replace_l)\n",
    "    \n",
    "    \n",
    "    # turn the set back into a list and sort it, for easier viewing\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ac70922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = can \n",
      "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
      "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n",
      "\n",
      "Number of outputs of replace_letter('at') is 50\n"
     ]
    }
   ],
   "source": [
    "replace_l = replace_letter(word='can', verbose=True)\n",
    "print()\n",
    "print(f\"Number of outputs of replace_letter('at') is {len(replace_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3c6d1",
   "metadata": {},
   "source": [
    "### Insert Operations\n",
    "I will implement a insert_letter() function that takes in a word and returns a list with a letter inserted at every offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adea17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "    insert_l = [L+N+R for L,R in split_l for N in letters]\n",
    "       \n",
    "    \n",
    "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    \n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb3248dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word at \n",
      "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
      "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
      "\n",
      "Number of strings output by insert_letter('at') is 78\n"
     ]
    }
   ],
   "source": [
    "insert_l = insert_letter('at', True)\n",
    "print()\n",
    "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f300bd",
   "metadata": {},
   "source": [
    "<HR></HR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ee24f",
   "metadata": {},
   "source": [
    "## Preforming All Operations\n",
    "Now that I have implemented the string manipulations, I will create two functions that, given a word, will return all the possible single and double edits on that word. These will be edit_one_letter() and edit_two_letters()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c168b",
   "metadata": {},
   "source": [
    "### One Letter Edit\n",
    "I will implement the edit_one_letter() function to get all the possible edits that are one edit away from a word. The edits  consist of the replace, insert, delete, and optionally the switch operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9976fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    \n",
    "    functions = [delete_letter, insert_letter, replace_letter]\n",
    "    if allow_switches:\n",
    "        functions.append(switch_letter)\n",
    "        \n",
    "    for func in functions:\n",
    "        candidates = func(word)\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            edit_one_set.add(candidate)\n",
    "    \n",
    "    \n",
    "    # return this as a set and not a list\n",
    "    return set(edit_one_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3042b1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word at \n",
      "edit_one_l \n",
      "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
      "\n",
      "The type of the returned object should be a set <class 'set'>\n",
      "Number of outputs from edit_one_letter('at') is 129\n"
     ]
    }
   ],
   "source": [
    "tmp_word = \"at\"\n",
    "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
    "# turn this into a list to sort it, in order to view it\n",
    "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
    "\n",
    "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
    "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
    "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d270d9",
   "metadata": {},
   "source": [
    "### Two Letter Edit\n",
    "Now you can generalize this to implement to get two edits on a word. To do so, you would have to get all the possible edits on a single word and then for each modified word, you would have to modify it again.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d682895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    one_set_candidates = edit_one_letter(word, allow_switches)\n",
    "    candidates_l = list(one_set_candidates)\n",
    "    \n",
    "    for candidate in candidates_l:\n",
    "        second_degree_candidate = edit_one_letter(candidate, allow_switches)\n",
    "        \n",
    "        for cand in list(second_degree_candidate):\n",
    "            edit_two_set.add(cand)\n",
    "            \n",
    "    for cand in candidates_l:\n",
    "        edit_two_set.add(cand)\n",
    "        \n",
    "    \n",
    "    # return this as a set instead of a list\n",
    "    return set(edit_two_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7c5b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings with edit distance of two: 2654\n",
      "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
      "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
      "The data type of the returned object should be a set <class 'set'>\n",
      "Number of strings that are 2 edit distances from 'at' is 7154\n"
     ]
    }
   ],
   "source": [
    "tmp_edit_two_set = edit_two_letters(\"a\")\n",
    "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
    "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
    "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
    "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
    "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
    "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e629f",
   "metadata": {},
   "source": [
    "<HR></HR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf3c14",
   "metadata": {},
   "source": [
    "# Suggest Words\n",
    "Now I will use edit_two_letters function to get a set of all the possible 2 edits on your word. then using those strings to get the most probable word you meant to type a.k.a your typing suggestion.<br>\n",
    "* If the word is in the vocabulary, suggest the word. \n",
    "* Otherwise, if there are suggestions from **edit_one_letter** that are in the vocabulary, use those. \n",
    "* Otherwise, if there are suggestions from **edit_two_letters** that are in the vocabulary, use those. \n",
    "* Otherwise, suggest the input word.*  \n",
    "* The idea is that words generated from fewer edits are more likely than words with more edits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2811f0",
   "metadata": {},
   "source": [
    "Implementing **get_corrections** function, which returns a list of zero to n possible suggestion tuples of the form (word, probability_of_word).\n",
    "\n",
    "Select the n best suggestions. There may be fewer than n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19deadaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    #create suggestions    \n",
    "    \n",
    "    one_edits = list(edit_one_letter(word))\n",
    "    two_edits = list(edit_two_letters(word))\n",
    "    \n",
    "    if word in vocab:\n",
    "        suggestions.append(word)\n",
    "    elif one_edits:\n",
    "        for edit in one_edits:\n",
    "            if edit in vocab:\n",
    "                suggestions.append(edit)\n",
    "    elif two_edits:\n",
    "        for edit in two_edits:\n",
    "            if edit in vocab:\n",
    "                suggestions.append(edit)\n",
    "    else :\n",
    "        pass\n",
    "    \n",
    "    #determine probability of suggestions\n",
    "    probabilities = [probs[suggest] for suggest in suggestions]\n",
    "    \n",
    "    #Get all your best words and return the most probable top n_suggested words as n_best\n",
    "    sorted_idx = np.argsort(np.array(probabilities))[::-1][:n]\n",
    "    suggestions = np.array(suggestions)[sorted_idx]\n",
    "    probabilities = np.array(probabilities)[sorted_idx]\n",
    "    n_best = list(zip(suggestions,probabilities))\n",
    "        \n",
    "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f285200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  kids \n",
      "suggestions =  ['kiss' 'bids']\n",
      "word 0: kiss, probability 0.000149\n",
      "word 1: bids, probability 0.000075\n",
      "data type of corrections <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "my_word = 'kids' \n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) \n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
    "\n",
    "print(f\"data type of corrections {type(tmp_corrections)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d011f",
   "metadata": {},
   "source": [
    "<HR></HR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24333dc1",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Since this Auto Correct is based on probablisitic model, it might not work properly.<br>\n",
    "**Example**:<br>\n",
    "`ands in your pants`, the correct word is **ants**, but since **and** has a higher probability the model will suggest **and**<br>\n",
    "#### Future Work:\n",
    "we can overcome this problem by gathering the context of the sentence using more complex models like RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df44ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
